{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "# gpu 메모리 최대로 잡는 것을 방지\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "model = load_model('C:/Users/s_csmscox/jupyterSave/eye_blink/eye_blink_CNN_ImgGen1_FT.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CascadeClassifier 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('C:/Users/s_csmscox/anaconda3/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('C:/Users/s_csmscox/anaconda3/Lib/site-packages/cv2/data/haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread('./face.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 눈 찾아내기\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "        img_trim = img[y+ey:y+ey+eh, x+ex:x+ex+ew]\n",
    "        \n",
    "        \n",
    "plt.imshow(img_trim)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "img_size =32\n",
    "img_trim = Image.fromarray(img_trim)\n",
    "img_trim = img_trim.resize((img_size, img_size))\n",
    "img_trim = np.asarray(img_trim)\n",
    "\n",
    "plt.imshow(img_trim)\n",
    "plt.show()\n",
    "\n",
    "img_trim = img_trim/255\n",
    "\n",
    "img_trim = img_trim.reshape(1,img_size,img_size,3)\n",
    "pred = model.predict(img_trim)\n",
    "\n",
    "if np.argmax(pred) == 0:\n",
    "    print(\"예측 : 졸음\")\n",
    "else:\n",
    "    print(\"예측 : 안졸음\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dlib - Face Landmark 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 : 안졸음\n",
      "예측 : 안졸음\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/s_csmscox/jupyterSave/eye_blink/shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "img_size = (32, 32)\n",
    "\n",
    "def mse(imageA, imageB):\n",
    "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "    err /= float(imageA.shape[0] * imageB.shape[1])\n",
    "    return err\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "    x1, y1 = np.amin(eye_points, axis=0)\n",
    "    x2, y2 = np.amax(eye_points, axis=0)\n",
    "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "    \n",
    "    w = (x2 - x1) * 1.2\n",
    "    h = w * img_size[1] / img_size[0]\n",
    "    \n",
    "    margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "    min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "    max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "    eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "    eye_img = img[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "    \n",
    "    return eye_img, eye_rect\n",
    "\n",
    "img = cv2.imread('C:/Users/s_csmscox/jupyterSave/eye_blink/face4.jpg')\n",
    "\n",
    "faces = detector(img)\n",
    "\n",
    "for face in faces:\n",
    "    shapes = predictor(img, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "    \n",
    "    eye_img_l, eye_rect_l = crop_eye(img, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(img, eye_points=shapes[42:48])\n",
    "    \n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=img_size)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=img_size)\n",
    "    \n",
    "    # 왼쪽 눈\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, img_size[1], img_size[0], 3)).astype(np.float32)\n",
    "    eye_input_l = eye_input_l/255\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_l = np.argmax(pred_l)\n",
    "\n",
    "    # 오른쪽 눈\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, img_size[1], img_size[0], 3)).astype(np.float32)\n",
    "    eye_input_r = eye_input_r/255\n",
    "\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "    pred_r = np.argmax(pred_r)\n",
    "    \n",
    "    # 눈에 직사각형 그리기\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, str(pred_l), tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, str(pred_r), tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    \n",
    "    cv2.imshow('image', img)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # 두 눈 다 감은 경우 졸음으로 예측\n",
    "    if pred_l == 0 and pred_r == 0:\n",
    "        print(\"예측 : 졸음\")\n",
    "    else:\n",
    "        print(\"예측 : 안졸음\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 영상을 이용\n",
    "\n",
    "cap = cv2.VideoCapture('C:/Users/s_csmscox/jupyterSave/eye_blink/face2.mp4')\n",
    "\n",
    "n_count = 0\n",
    "\n",
    "ret, img = cap.read()\n",
    "img = cv2.resize(img, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "while True:\n",
    "#     frame_pos = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "#     frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    \n",
    "#     print(\"%d/%d\" %(frame_pos, frame_count))\n",
    "    ret, compare_img = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    compare_img = cv2.resize(compare_img, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "    faces = detector(compare_img)\n",
    "    \n",
    "    for face in faces:\n",
    "        shapes = predictor(compare_img, face)\n",
    "        shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "        eye_img_l, eye_rect_l = crop_eye(compare_img, eye_points=shapes[36:42])\n",
    "        eye_img_r, eye_rect_r = crop_eye(compare_img, eye_points=shapes[42:48])\n",
    "\n",
    "        eye_img_l = cv2.resize(eye_img_l, dsize=img_size)\n",
    "        eye_img_r = cv2.resize(eye_img_r, dsize=img_size)\n",
    "\n",
    "        # 왼쪽 눈\n",
    "        eye_input_l = eye_img_l.copy().reshape((1, img_size[1], img_size[0], 3)).astype(np.float32)\n",
    "        eye_input_l = eye_input_l/255\n",
    "\n",
    "        pred_l = model.predict(eye_input_l)\n",
    "        pred_l = np.argmax(pred_l)\n",
    "\n",
    "        # 오른쪽 눈\n",
    "        eye_input_r = eye_img_r.copy().reshape((1, img_size[1], img_size[0], 3)).astype(np.float32)\n",
    "        eye_input_r = eye_input_r/255\n",
    "\n",
    "        pred_r = model.predict(eye_input_r)\n",
    "        pred_r = np.argmax(pred_r)\n",
    "\n",
    "        # visualize\n",
    "#         state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "#         state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "#         state_l = state_l % pred_l\n",
    "#         state_r = state_r % pred_r\n",
    "\n",
    "        # 눈에 직사각형 그리기\n",
    "        cv2.rectangle(compare_img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "        cv2.rectangle(compare_img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "        cv2.putText(compare_img, str(pred_l), tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "        cv2.putText(compare_img, str(pred_r), tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "        # 두 눈 다 감은 경우 졸음으로 예측\n",
    "        if pred_l == 0 and pred_r == 0:\n",
    "            n_count += 1\n",
    "        else:\n",
    "            n_count = 0\n",
    "\n",
    "        # n_count가 10 초과하면 경고 메세지\n",
    "        if n_count > 10:\n",
    "            # BGR\n",
    "            cv2.putText(compare_img,\"Wake up!(eye_blink)\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
    "\n",
    "        # 원본과 움직인 이미지를 비교해서 mse가 일정 이상일 시 움직인것으로 판단\n",
    "        mse_val = mse(img, compare_img)\n",
    "\n",
    "        if mse_val > 2000:\n",
    "            cv2.putText(compare_img,\"Wake up!(movement)\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)\n",
    "\n",
    "    cv2.imshow('result', compare_img)\n",
    "\n",
    "    # ESC 누르면 영상 종료\n",
    "    if cv2.waitKey(27) > 0:\n",
    "        break\n",
    "\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
