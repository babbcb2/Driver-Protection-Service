{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54332 images belonging to 2 classes.\n",
      "Found 13585 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_dir = 'C:/Users/s_csmscox/jupyterSave/eye_blink/train'\n",
    "validation_dir = 'C:/Users/s_csmscox/jupyterSave/eye_blink/valid'\n",
    "\n",
    "batch_size = 1000\n",
    "img_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator()\n",
    "\n",
    "# train_datagen = ImageDataGenerator(rescale=1/255,\n",
    "#                                    rotation_range=20,  # 지정된 각도 범위내에서 임의로 원본 이미지를 회전\n",
    "#                                    width_shift_range=0.1,\n",
    "#                                    height_shift_range=0.1,\n",
    "#                                    zoom_range=0.1,    #  1-수치 혹은 1+수치만큼 확대 및 축소\n",
    "#                                    )\n",
    "\n",
    "\n",
    "\n",
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_size,img_size),                      \n",
    "    batch_size=batch_size,     \n",
    "    class_mode='categorical'                    \n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(img_size,img_size),                       \n",
    "    batch_size=batch_size,    \n",
    "    class_mode='categorical'                    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Model: \"efficientnetb0\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling (Rescaling)           (None, 32, 32, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 32, 32, 3)    7           rescaling[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv_pad (ZeroPadding2D)   (None, 33, 33, 3)    0           normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 16, 16, 32)   864         stem_conv_pad[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 16, 16, 32)   128         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 16, 16, 32)   0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 16, 16, 32)   288         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 16, 16, 32)   128         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 16, 16, 32)   0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 32)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 16, 16, 32)   0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 16, 16, 16)   512         block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 16, 16, 16)   64          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 16, 16, 96)   1536        block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 16, 16, 96)   384         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 16, 16, 96)   0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv_pad (ZeroPadding (None, 17, 17, 96)   0           block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 8, 8, 96)     864         block2a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 8, 8, 96)     384         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 8, 8, 96)     0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 96)           0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 8, 8, 96)     0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 8, 8, 24)     2304        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 8, 8, 24)     96          block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 8, 8, 144)    3456        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 8, 8, 144)    576         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 8, 8, 144)    0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 8, 8, 144)    1296        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 8, 8, 144)    576         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 8, 8, 144)    0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 144)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 8, 8, 144)    0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 8, 8, 24)     3456        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 8, 8, 24)     96          block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (Dropout)          (None, 8, 8, 24)     0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 8, 8, 24)     0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 8, 8, 144)    3456        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 8, 8, 144)    576         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 8, 8, 144)    0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv_pad (ZeroPadding (None, 11, 11, 144)  0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 4, 4, 144)    3600        block3a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 4, 4, 144)    576         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 4, 4, 144)    0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 144)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 4, 4, 144)    0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 4, 4, 40)     5760        block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 4, 4, 40)     160         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 4, 4, 240)    9600        block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 4, 4, 240)    960         block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 4, 4, 240)    0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 4, 4, 240)    6000        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 4, 4, 240)    960         block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 4, 4, 240)    0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 240)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 4, 4, 240)    0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 4, 4, 40)     9600        block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 4, 4, 40)     160         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (Dropout)          (None, 4, 4, 40)     0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 4, 4, 40)     0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 4, 4, 240)    9600        block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 4, 4, 240)    960         block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 4, 4, 240)    0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv_pad (ZeroPadding (None, 5, 5, 240)    0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 2, 2, 240)    2160        block4a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 2, 2, 240)    960         block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 2, 2, 240)    0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 240)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 2, 2, 240)    0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 2, 2, 80)     19200       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 2, 2, 80)     320         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 2, 2, 480)    38400       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 2, 2, 480)    1920        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 2, 2, 480)    0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 2, 2, 480)    4320        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 2, 2, 480)    1920        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 2, 2, 480)    0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 480)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 2, 2, 480)    0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 2, 2, 80)     38400       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 2, 2, 80)     320         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (Dropout)          (None, 2, 2, 80)     0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 2, 2, 80)     0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 2, 2, 480)    38400       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 2, 2, 480)    1920        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 2, 2, 480)    0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 2, 2, 480)    4320        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 2, 2, 480)    1920        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 2, 2, 480)    0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 480)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 2, 2, 480)    0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 2, 2, 80)     38400       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 2, 2, 80)     320         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (Dropout)          (None, 2, 2, 80)     0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 2, 2, 80)     0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 2, 2, 480)    38400       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 2, 2, 480)    1920        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 2, 2, 480)    0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 2, 2, 480)    12000       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 2, 2, 480)    1920        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 2, 2, 480)    0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 480)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 2, 2, 480)    0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 2, 2, 112)    53760       block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 2, 2, 112)    448         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 2, 2, 672)    75264       block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 2, 2, 672)    2688        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 2, 2, 672)    0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 2, 2, 672)    16800       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 2, 2, 672)    2688        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 2, 2, 672)    0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 672)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 2, 2, 672)    0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 2, 2, 112)    75264       block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 2, 2, 112)    448         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (Dropout)          (None, 2, 2, 112)    0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 2, 2, 112)    0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 2, 2, 672)    75264       block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 2, 2, 672)    2688        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 2, 2, 672)    0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 2, 2, 672)    16800       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 2, 2, 672)    2688        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 2, 2, 672)    0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 672)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 2, 2, 672)    0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 2, 2, 112)    75264       block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 2, 2, 112)    448         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (Dropout)          (None, 2, 2, 112)    0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 2, 2, 112)    0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 2, 2, 672)    75264       block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 2, 2, 672)    2688        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 2, 2, 672)    0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv_pad (ZeroPadding (None, 5, 5, 672)    0           block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 1, 1, 672)    16800       block6a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 1, 1, 672)    2688        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 1, 1, 672)    0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 672)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 1, 1, 672)    0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 1, 1, 192)    129024      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 1, 1, 192)    768         block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 1, 1, 1152)   221184      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 1, 1, 1152)   4608        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 1, 1, 1152)   0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 1, 1, 1152)   28800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 1, 1, 1152)   4608        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 1, 1, 1152)   0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1152)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 1, 1, 1152)   0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 1, 1, 192)    221184      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 1, 1, 192)    768         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (Dropout)          (None, 1, 1, 192)    0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 1, 1, 192)    0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 1, 1, 1152)   221184      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 1, 1, 1152)   4608        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 1, 1, 1152)   0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 1, 1, 1152)   28800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 1, 1, 1152)   4608        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 1, 1, 1152)   0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1152)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 1, 1, 1152)   0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 1, 1, 192)    221184      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 1, 1, 192)    768         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (Dropout)          (None, 1, 1, 192)    0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 1, 1, 192)    0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 1, 1, 1152)   221184      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 1, 1, 1152)   4608        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 1, 1, 1152)   0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 1, 1, 1152)   28800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 1, 1, 1152)   4608        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 1, 1, 1152)   0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1152)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 1, 1, 1152)   0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 1, 1, 192)    221184      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 1, 1, 192)    768         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (Dropout)          (None, 1, 1, 192)    0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 1, 1, 192)    0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 1, 1, 1152)   221184      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 1, 1, 1152)   4608        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 1, 1, 1152)   0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 1, 1, 1152)   10368       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 1, 1, 1152)   4608        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 1, 1, 1152)   0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1152)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 1, 1, 1152)   0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 1, 1, 320)    368640      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 1, 1, 320)    1280        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 1, 1, 1280)   409600      block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 1, 1, 1280)   5120        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 1, 1, 1280)   0           top_bn[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,049,571\n",
      "Trainable params: 0\n",
      "Non-trainable params: 4,049,571\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb0 (Functional)  (None, 1, 1, 1280)        4049571   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               655872    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 4,869,925\n",
      "Trainable params: 820,354\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# gpu 메모리 최대로 잡는 것을 방지\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# 모델 구축\n",
    "\n",
    "# EfficientNetB0 모델 불러오기\n",
    "pre_trained_model = EfficientNetB0(include_top=False, weights='imagenet',\n",
    "                                  input_shape=(img_size, img_size, 3))\n",
    "pre_trained_model.trainable = False\n",
    "pre_trained_model.summary()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(pre_trained_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu', kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "55/54 [==============================] - 18s 331ms/step - loss: 0.0798 - accuracy: 0.9710 - val_loss: 0.0705 - val_accuracy: 0.9751\n",
      "Epoch 2/100\n",
      "55/54 [==============================] - 18s 327ms/step - loss: 0.0794 - accuracy: 0.9706 - val_loss: 0.0713 - val_accuracy: 0.9745\n",
      "Epoch 3/100\n",
      "55/54 [==============================] - 18s 331ms/step - loss: 0.0790 - accuracy: 0.9712 - val_loss: 0.0708 - val_accuracy: 0.9745\n",
      "Epoch 4/100\n",
      "55/54 [==============================] - 19s 341ms/step - loss: 0.0787 - accuracy: 0.9710 - val_loss: 0.0727 - val_accuracy: 0.9736\n",
      "Epoch 5/100\n",
      "55/54 [==============================] - 18s 330ms/step - loss: 0.0780 - accuracy: 0.9719 - val_loss: 0.0704 - val_accuracy: 0.9745\n",
      "Epoch 6/100\n",
      "55/54 [==============================] - 18s 333ms/step - loss: 0.0777 - accuracy: 0.9711 - val_loss: 0.0702 - val_accuracy: 0.9749\n",
      "Epoch 7/100\n",
      "55/54 [==============================] - 18s 332ms/step - loss: 0.0797 - accuracy: 0.9708 - val_loss: 0.0698 - val_accuracy: 0.9750\n",
      "Epoch 8/100\n",
      "55/54 [==============================] - 18s 325ms/step - loss: 0.0793 - accuracy: 0.9703 - val_loss: 0.0703 - val_accuracy: 0.9745\n",
      "Epoch 9/100\n",
      "55/54 [==============================] - 18s 325ms/step - loss: 0.0783 - accuracy: 0.9708 - val_loss: 0.0697 - val_accuracy: 0.9751\n",
      "Epoch 10/100\n",
      "55/54 [==============================] - 18s 325ms/step - loss: 0.0781 - accuracy: 0.9722 - val_loss: 0.0696 - val_accuracy: 0.9749\n",
      "Epoch 11/100\n",
      "55/54 [==============================] - 18s 325ms/step - loss: 0.0775 - accuracy: 0.9715 - val_loss: 0.0695 - val_accuracy: 0.9748\n",
      "Epoch 12/100\n",
      "55/54 [==============================] - 18s 324ms/step - loss: 0.0772 - accuracy: 0.9717 - val_loss: 0.0693 - val_accuracy: 0.9756\n",
      "Epoch 13/100\n",
      "55/54 [==============================] - 18s 324ms/step - loss: 0.0780 - accuracy: 0.9714 - val_loss: 0.0705 - val_accuracy: 0.9743\n",
      "Epoch 14/100\n",
      "55/54 [==============================] - 18s 326ms/step - loss: 0.0772 - accuracy: 0.9717 - val_loss: 0.0691 - val_accuracy: 0.9748\n",
      "Epoch 15/100\n",
      "55/54 [==============================] - 18s 332ms/step - loss: 0.0762 - accuracy: 0.9721 - val_loss: 0.0701 - val_accuracy: 0.9750\n",
      "Epoch 16/100\n",
      "55/54 [==============================] - 18s 326ms/step - loss: 0.0774 - accuracy: 0.9718 - val_loss: 0.0701 - val_accuracy: 0.9746\n",
      "Epoch 17/100\n",
      "55/54 [==============================] - 18s 327ms/step - loss: 0.0762 - accuracy: 0.9721 - val_loss: 0.0684 - val_accuracy: 0.9753\n",
      "Epoch 18/100\n",
      "55/54 [==============================] - 18s 330ms/step - loss: 0.0775 - accuracy: 0.9714 - val_loss: 0.0688 - val_accuracy: 0.9756\n",
      "Epoch 19/100\n",
      "55/54 [==============================] - 18s 330ms/step - loss: 0.0767 - accuracy: 0.9718 - val_loss: 0.0687 - val_accuracy: 0.9754\n",
      "Epoch 20/100\n",
      "55/54 [==============================] - 18s 325ms/step - loss: 0.0770 - accuracy: 0.9722 - val_loss: 0.0682 - val_accuracy: 0.9755\n",
      "Epoch 21/100\n",
      "55/54 [==============================] - 18s 324ms/step - loss: 0.0749 - accuracy: 0.9731 - val_loss: 0.0683 - val_accuracy: 0.9757\n",
      "Epoch 22/100\n",
      "55/54 [==============================] - 18s 324ms/step - loss: 0.0759 - accuracy: 0.9723 - val_loss: 0.0682 - val_accuracy: 0.9753\n",
      "Epoch 23/100\n",
      "55/54 [==============================] - 18s 325ms/step - loss: 0.0753 - accuracy: 0.9726 - val_loss: 0.0681 - val_accuracy: 0.9759\n",
      "Epoch 24/100\n",
      "55/54 [==============================] - 18s 325ms/step - loss: 0.0747 - accuracy: 0.9729 - val_loss: 0.0685 - val_accuracy: 0.9753\n",
      "Epoch 25/100\n",
      "55/54 [==============================] - 18s 324ms/step - loss: 0.0770 - accuracy: 0.9713 - val_loss: 0.0684 - val_accuracy: 0.9753\n",
      "Epoch 26/100\n",
      "55/54 [==============================] - 18s 325ms/step - loss: 0.0766 - accuracy: 0.9724 - val_loss: 0.0675 - val_accuracy: 0.9758\n",
      "Epoch 27/100\n",
      "55/54 [==============================] - 18s 325ms/step - loss: 0.0763 - accuracy: 0.9719 - val_loss: 0.0677 - val_accuracy: 0.9753\n",
      "Epoch 28/100\n",
      "55/54 [==============================] - 18s 325ms/step - loss: 0.0755 - accuracy: 0.9719 - val_loss: 0.0677 - val_accuracy: 0.9755\n",
      "Epoch 29/100\n",
      "55/54 [==============================] - 18s 327ms/step - loss: 0.0746 - accuracy: 0.9723 - val_loss: 0.0683 - val_accuracy: 0.9756\n",
      "Epoch 30/100\n",
      "55/54 [==============================] - 18s 328ms/step - loss: 0.0736 - accuracy: 0.9736 - val_loss: 0.0679 - val_accuracy: 0.9750\n",
      "Epoch 31/100\n",
      "55/54 [==============================] - 18s 330ms/step - loss: 0.0754 - accuracy: 0.9727 - val_loss: 0.0674 - val_accuracy: 0.9760\n",
      "Epoch 32/100\n",
      "55/54 [==============================] - 18s 330ms/step - loss: 0.0754 - accuracy: 0.9725 - val_loss: 0.0677 - val_accuracy: 0.9759\n",
      "Epoch 33/100\n",
      "55/54 [==============================] - 18s 329ms/step - loss: 0.0741 - accuracy: 0.9727 - val_loss: 0.0692 - val_accuracy: 0.9748\n",
      "Epoch 34/100\n",
      "55/54 [==============================] - 18s 329ms/step - loss: 0.0740 - accuracy: 0.9727 - val_loss: 0.0676 - val_accuracy: 0.9759\n",
      "Epoch 35/100\n",
      "55/54 [==============================] - 18s 328ms/step - loss: 0.0748 - accuracy: 0.9722 - val_loss: 0.0677 - val_accuracy: 0.9760\n",
      "Epoch 36/100\n",
      "55/54 [==============================] - 18s 325ms/step - loss: 0.0747 - accuracy: 0.9725 - val_loss: 0.0672 - val_accuracy: 0.9757\n",
      "Epoch 37/100\n",
      "55/54 [==============================] - 18s 324ms/step - loss: 0.0725 - accuracy: 0.9732 - val_loss: 0.0691 - val_accuracy: 0.9742\n",
      "Epoch 38/100\n",
      "55/54 [==============================] - 18s 324ms/step - loss: 0.0732 - accuracy: 0.9733 - val_loss: 0.0668 - val_accuracy: 0.9758\n",
      "Epoch 39/100\n",
      "55/54 [==============================] - 18s 325ms/step - loss: 0.0729 - accuracy: 0.9729 - val_loss: 0.0667 - val_accuracy: 0.9756\n",
      "Epoch 40/100\n",
      "55/54 [==============================] - 18s 329ms/step - loss: 0.0718 - accuracy: 0.9735 - val_loss: 0.0671 - val_accuracy: 0.9756\n",
      "Epoch 41/100\n",
      "55/54 [==============================] - 18s 329ms/step - loss: 0.0735 - accuracy: 0.9729 - val_loss: 0.0662 - val_accuracy: 0.9762\n",
      "Epoch 42/100\n",
      "55/54 [==============================] - 18s 326ms/step - loss: 0.0728 - accuracy: 0.9739 - val_loss: 0.0660 - val_accuracy: 0.9762\n",
      "Epoch 43/100\n",
      "55/54 [==============================] - 18s 326ms/step - loss: 0.0723 - accuracy: 0.9734 - val_loss: 0.0666 - val_accuracy: 0.9760\n",
      "Epoch 44/100\n",
      "55/54 [==============================] - 18s 326ms/step - loss: 0.0727 - accuracy: 0.9728 - val_loss: 0.0660 - val_accuracy: 0.9761\n",
      "Epoch 45/100\n",
      "55/54 [==============================] - 18s 330ms/step - loss: 0.0724 - accuracy: 0.9737 - val_loss: 0.0662 - val_accuracy: 0.9762\n",
      "Epoch 46/100\n",
      "55/54 [==============================] - 18s 326ms/step - loss: 0.0731 - accuracy: 0.9736 - val_loss: 0.0661 - val_accuracy: 0.9759\n",
      "Epoch 47/100\n",
      "55/54 [==============================] - 18s 330ms/step - loss: 0.0723 - accuracy: 0.9737 - val_loss: 0.0681 - val_accuracy: 0.9748\n",
      "Epoch 48/100\n",
      "55/54 [==============================] - 18s 330ms/step - loss: 0.0738 - accuracy: 0.9731 - val_loss: 0.0675 - val_accuracy: 0.9754\n",
      "Epoch 49/100\n",
      "55/54 [==============================] - 18s 329ms/step - loss: 0.0728 - accuracy: 0.9734 - val_loss: 0.0666 - val_accuracy: 0.9756\n",
      "Epoch 50/100\n",
      "55/54 [==============================] - 18s 333ms/step - loss: 0.0718 - accuracy: 0.9741 - val_loss: 0.0657 - val_accuracy: 0.9767\n",
      "Epoch 51/100\n",
      "55/54 [==============================] - 18s 328ms/step - loss: 0.0730 - accuracy: 0.9733 - val_loss: 0.0660 - val_accuracy: 0.9764\n",
      "Epoch 52/100\n",
      "55/54 [==============================] - 18s 328ms/step - loss: 0.0719 - accuracy: 0.9736 - val_loss: 0.0654 - val_accuracy: 0.9762\n",
      "Epoch 53/100\n",
      "55/54 [==============================] - 18s 327ms/step - loss: 0.0723 - accuracy: 0.9734 - val_loss: 0.0654 - val_accuracy: 0.9767\n",
      "Epoch 54/100\n",
      "55/54 [==============================] - 18s 327ms/step - loss: 0.0708 - accuracy: 0.9738 - val_loss: 0.0667 - val_accuracy: 0.9755\n",
      "Epoch 55/100\n",
      "55/54 [==============================] - 18s 327ms/step - loss: 0.0721 - accuracy: 0.9733 - val_loss: 0.0663 - val_accuracy: 0.9759\n",
      "Epoch 56/100\n",
      "55/54 [==============================] - 18s 331ms/step - loss: 0.0713 - accuracy: 0.9741 - val_loss: 0.0652 - val_accuracy: 0.9762\n",
      "Epoch 57/100\n",
      "55/54 [==============================] - 18s 328ms/step - loss: 0.0701 - accuracy: 0.9744 - val_loss: 0.0651 - val_accuracy: 0.9761\n",
      "Epoch 58/100\n",
      "55/54 [==============================] - 18s 332ms/step - loss: 0.0706 - accuracy: 0.9738 - val_loss: 0.0665 - val_accuracy: 0.9755\n",
      "Epoch 59/100\n",
      "55/54 [==============================] - 18s 332ms/step - loss: 0.0714 - accuracy: 0.9739 - val_loss: 0.0652 - val_accuracy: 0.9761\n",
      "Epoch 60/100\n",
      "55/54 [==============================] - 18s 328ms/step - loss: 0.0704 - accuracy: 0.9739 - val_loss: 0.0675 - val_accuracy: 0.9748\n",
      "Epoch 61/100\n",
      "55/54 [==============================] - 18s 326ms/step - loss: 0.0703 - accuracy: 0.9739 - val_loss: 0.0648 - val_accuracy: 0.9768\n",
      "Epoch 62/100\n",
      "55/54 [==============================] - 18s 325ms/step - loss: 0.0704 - accuracy: 0.9742 - val_loss: 0.0642 - val_accuracy: 0.9770\n",
      "Epoch 63/100\n",
      "55/54 [==============================] - 18s 329ms/step - loss: 0.0693 - accuracy: 0.9745 - val_loss: 0.0641 - val_accuracy: 0.9772\n",
      "Epoch 64/100\n",
      "55/54 [==============================] - 18s 327ms/step - loss: 0.0705 - accuracy: 0.9741 - val_loss: 0.0647 - val_accuracy: 0.9767\n",
      "Epoch 65/100\n",
      "55/54 [==============================] - 18s 328ms/step - loss: 0.0711 - accuracy: 0.9741 - val_loss: 0.0637 - val_accuracy: 0.9768\n",
      "Epoch 66/100\n",
      "55/54 [==============================] - 18s 330ms/step - loss: 0.0709 - accuracy: 0.9744 - val_loss: 0.0638 - val_accuracy: 0.9772\n",
      "Epoch 67/100\n",
      "55/54 [==============================] - 18s 329ms/step - loss: 0.0705 - accuracy: 0.9742 - val_loss: 0.0640 - val_accuracy: 0.9770\n",
      "Epoch 68/100\n",
      "55/54 [==============================] - 18s 327ms/step - loss: 0.0703 - accuracy: 0.9744 - val_loss: 0.0643 - val_accuracy: 0.9770\n",
      "Epoch 69/100\n",
      "55/54 [==============================] - 18s 327ms/step - loss: 0.0681 - accuracy: 0.9753 - val_loss: 0.0642 - val_accuracy: 0.9767\n",
      "Epoch 70/100\n",
      "55/54 [==============================] - 18s 329ms/step - loss: 0.0688 - accuracy: 0.9758 - val_loss: 0.0635 - val_accuracy: 0.9775\n",
      "Epoch 71/100\n",
      "55/54 [==============================] - 19s 340ms/step - loss: 0.0700 - accuracy: 0.9744 - val_loss: 0.0648 - val_accuracy: 0.9763\n",
      "Epoch 72/100\n",
      "55/54 [==============================] - 18s 334ms/step - loss: 0.0701 - accuracy: 0.9747 - val_loss: 0.0640 - val_accuracy: 0.9770\n",
      "Epoch 73/100\n",
      "55/54 [==============================] - 19s 342ms/step - loss: 0.0698 - accuracy: 0.9743 - val_loss: 0.0635 - val_accuracy: 0.9770\n",
      "Epoch 74/100\n",
      "55/54 [==============================] - 18s 327ms/step - loss: 0.0696 - accuracy: 0.9745 - val_loss: 0.0634 - val_accuracy: 0.9769\n",
      "Epoch 75/100\n",
      "55/54 [==============================] - 18s 326ms/step - loss: 0.0688 - accuracy: 0.9749 - val_loss: 0.0635 - val_accuracy: 0.9775\n",
      "Epoch 76/100\n",
      "55/54 [==============================] - 18s 327ms/step - loss: 0.0685 - accuracy: 0.9750 - val_loss: 0.0647 - val_accuracy: 0.9761\n",
      "Epoch 77/100\n",
      "55/54 [==============================] - 18s 327ms/step - loss: 0.0694 - accuracy: 0.9751 - val_loss: 0.0639 - val_accuracy: 0.9769\n",
      "Epoch 78/100\n",
      "55/54 [==============================] - 18s 330ms/step - loss: 0.0700 - accuracy: 0.9745 - val_loss: 0.0641 - val_accuracy: 0.9767\n",
      "Epoch 79/100\n",
      "55/54 [==============================] - 18s 329ms/step - loss: 0.0694 - accuracy: 0.9747 - val_loss: 0.0649 - val_accuracy: 0.9756\n",
      "Epoch 80/100\n",
      "55/54 [==============================] - 18s 331ms/step - loss: 0.0699 - accuracy: 0.9743 - val_loss: 0.0632 - val_accuracy: 0.9774\n",
      "Epoch 81/100\n",
      "55/54 [==============================] - 18s 330ms/step - loss: 0.0687 - accuracy: 0.9748 - val_loss: 0.0638 - val_accuracy: 0.9767\n",
      "Epoch 82/100\n",
      "55/54 [==============================] - 18s 330ms/step - loss: 0.0684 - accuracy: 0.9752 - val_loss: 0.0627 - val_accuracy: 0.9777\n",
      "Epoch 83/100\n",
      "55/54 [==============================] - 18s 329ms/step - loss: 0.0683 - accuracy: 0.9752 - val_loss: 0.0632 - val_accuracy: 0.9767\n",
      "Epoch 84/100\n",
      "55/54 [==============================] - 18s 328ms/step - loss: 0.0665 - accuracy: 0.9758 - val_loss: 0.0632 - val_accuracy: 0.9773\n",
      "Epoch 85/100\n",
      "55/54 [==============================] - 18s 328ms/step - loss: 0.0680 - accuracy: 0.9754 - val_loss: 0.0642 - val_accuracy: 0.9767\n",
      "Epoch 86/100\n",
      "55/54 [==============================] - 18s 328ms/step - loss: 0.0680 - accuracy: 0.9752 - val_loss: 0.0623 - val_accuracy: 0.9774\n",
      "Epoch 87/100\n",
      "55/54 [==============================] - 18s 326ms/step - loss: 0.0674 - accuracy: 0.9755 - val_loss: 0.0629 - val_accuracy: 0.9775\n",
      "Epoch 88/100\n",
      "55/54 [==============================] - 18s 326ms/step - loss: 0.0669 - accuracy: 0.9757 - val_loss: 0.0627 - val_accuracy: 0.9777\n",
      "Epoch 89/100\n",
      "55/54 [==============================] - 18s 326ms/step - loss: 0.0681 - accuracy: 0.9756 - val_loss: 0.0623 - val_accuracy: 0.9776\n",
      "Epoch 90/100\n",
      "55/54 [==============================] - 18s 327ms/step - loss: 0.0675 - accuracy: 0.9752 - val_loss: 0.0628 - val_accuracy: 0.9774\n",
      "Epoch 91/100\n",
      "55/54 [==============================] - 18s 326ms/step - loss: 0.0677 - accuracy: 0.9750 - val_loss: 0.0623 - val_accuracy: 0.9773\n",
      "Epoch 92/100\n",
      "55/54 [==============================] - 18s 325ms/step - loss: 0.0662 - accuracy: 0.9753 - val_loss: 0.0620 - val_accuracy: 0.9777\n",
      "Epoch 93/100\n",
      "55/54 [==============================] - 18s 326ms/step - loss: 0.0672 - accuracy: 0.9755 - val_loss: 0.0629 - val_accuracy: 0.9773\n",
      "Epoch 94/100\n",
      "55/54 [==============================] - 18s 329ms/step - loss: 0.0671 - accuracy: 0.9753 - val_loss: 0.0615 - val_accuracy: 0.9778\n",
      "Epoch 95/100\n",
      "55/54 [==============================] - 18s 332ms/step - loss: 0.0675 - accuracy: 0.9755 - val_loss: 0.0630 - val_accuracy: 0.9775\n",
      "Epoch 96/100\n",
      "55/54 [==============================] - 18s 329ms/step - loss: 0.0671 - accuracy: 0.9762 - val_loss: 0.0621 - val_accuracy: 0.9778\n",
      "Epoch 97/100\n",
      "55/54 [==============================] - 18s 331ms/step - loss: 0.0661 - accuracy: 0.9761 - val_loss: 0.0633 - val_accuracy: 0.9770\n",
      "Epoch 98/100\n",
      "55/54 [==============================] - 18s 331ms/step - loss: 0.0662 - accuracy: 0.9762 - val_loss: 0.0619 - val_accuracy: 0.9776\n",
      "Epoch 99/100\n",
      "55/54 [==============================] - 18s 326ms/step - loss: 0.0664 - accuracy: 0.9760 - val_loss: 0.0622 - val_accuracy: 0.9778\n",
      "Epoch 100/100\n",
      "55/54 [==============================] - 18s 326ms/step - loss: 0.0652 - accuracy: 0.9766 - val_loss: 0.0619 - val_accuracy: 0.9775\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience = 15) # 조기종료 콜백함수 정의\n",
    "\n",
    "# 데이터 개수 / batch_size\n",
    "steps_per_epoch = 54332 / batch_size\n",
    "val_steps = 13585 / batch_size\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=100,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=val_steps,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16981 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_dir = 'C:/Users/s_csmscox/jupyterSave/eye_blink/test'\n",
    "\n",
    "batch_size = 50\n",
    "img_size = 32\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_size,img_size),                      \n",
    "    batch_size=batch_size,     \n",
    "    class_mode='categorical'                    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluate --\n",
      "340/339 [==============================] - 5s 15ms/step - loss: 0.0584 - accuracy: 0.9796\n",
      "accuracy: 97.96%\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "\n",
    "steps = 16981 / batch_size\n",
    "\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate(test_generator, steps=steps)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/Users/s_csmscox/jupyterSave/eye_blink/eye_blink_EfficientNetB0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  파일 길이 :  8390\n",
      "0  :  C:/Users/s_csmscox/jupyterSave/eye_blink/test/0\\s0001_00002_0_0_0_0_0_01.png\n",
      "1  파일 길이 :  8591\n",
      "1  :  C:/Users/s_csmscox/jupyterSave/eye_blink/test/1\\s0001_01842_0_0_1_0_0_01.png\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import os,glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 이미지를 numpy 배열로 만들기\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "directory = 'C:/Users/s_csmscox/jupyterSave/eye_blink/test'\n",
    "categories = [\"0\",\"1\"] # dog = 1, cat = 0\n",
    "nb_classes = len(categories)\n",
    "\n",
    "w = 32\n",
    "h = 32\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, obj in enumerate(categories):\n",
    "\n",
    "    image_dir = directory + \"/\" + obj\n",
    "    files = glob.glob(image_dir+\"/*.png\")\n",
    "    print(obj, \" 파일 길이 : \", len(files))\n",
    "    \n",
    "    for i, f in enumerate(files):\n",
    "        img = cv2.imread(f, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        # 사이즈 조절\n",
    "        img = cv2.resize(img, (w,h))\n",
    "        \n",
    "        X.append(img)\n",
    "        y.append(idx)\n",
    "\n",
    "        if i % 10000 == 0:\n",
    "            print(obj, \" : \", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9597198e-01, 4.0279781e-03],\n",
       "       [8.8347578e-01, 1.1652415e-01],\n",
       "       [9.9495310e-01, 5.0468910e-03],\n",
       "       ...,\n",
       "       [2.0240283e-05, 9.9997973e-01],\n",
       "       [8.6710453e-03, 9.9132895e-01],\n",
       "       [4.3316380e-04, 9.9956685e-01]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "y_pred = np.argmax(y_pred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       close     0.9771    0.9810    0.9791      8390\n",
      "        open     0.9814    0.9775    0.9795      8591\n",
      "\n",
      "    accuracy                         0.9793     16981\n",
      "   macro avg     0.9793    0.9793    0.9793     16981\n",
      "weighted avg     0.9793    0.9793    0.9793     16981\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['close', 'open']\n",
    "print(classification_report(y, y_pred, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "early_stopping = EarlyStopping(patience = 15) # 조기종료 콜백함수 정의\n",
    "\n",
    "# 데이터 개수 / batch_size\n",
    "steps_per_epoch = 54332 / batch_size\n",
    "val_steps = 13585 / batch_size\n",
    "\n",
    "set_trainable = False\n",
    "for layer in pre_trained_model.layers:\n",
    "    if layer.name == 'conv2d_386':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-7), loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=100,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=val_steps,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_dir = 'C:/Users/s_csmscox/jupyterSave/eye_blink/test'\n",
    "\n",
    "batch_size = 50\n",
    "img_size = 32\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_size,img_size),                      \n",
    "    batch_size=batch_size,     \n",
    "    class_mode='categorical'                    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "\n",
    "steps = 16981 / batch_size\n",
    "\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate(test_generator, steps=steps)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
